Agentic Gen AI for Security Baseline Automation
Short Description (Elevator Pitch):
Our goal is to use a Bedrock-powered agentic AI system that automatically generates and validates secure configuration baselines. Given an AWS service such as EC2, the foundation model proposes a set of security configuration requirements, each with a clear objective, description, and an infrastructure-as-code “definition of good” that showcases the expected configuration of a compliant service instance. Uniquely, the AI then uses Amazon Bedrock Agents to test each requirement in a sandboxed AWS environment, deploying resources and attempting actions (such as a simulated attack or misconfiguration) to ensure the requirement truly meets its objective. If a test fails, the AI refines the configuration and retries, iterating until the security requirement is confirmed effective or providing an explanation if it cannot be validated. The result is an intelligent, autonomous system that not only suggests best-practice cloud configurations but also proves they work, significantly reducing human effort and error in creating and validating secure baseline requirements.
Describe your Hackathon Idea:
Our hackathon project will build an AI-driven “security baseline copilot” for C3 engineers. The idea is to leverage a Large Language Model (LLM) via Amazon Bedrock to generate security requirements for any given AWS service, and an integrated agent that executes AWS Lambda functions to create resources and validate those requirements in real-time. For example, if the C3 engineer asks for an EC2 baseline, the Bedrock model might output a requirement such as “Instance Metadata Service v1 must be disabled” with the recommended configuration:
MetadataOptions: {
HttpTokens: "required"
}
The agent then automatically launches a test EC2 instance with that setting and attempts to access the legacy v1 metadata endpoint. If the instance’s IMDSv1 is indeed unreachable (as expected), the requirement is marked valid. If the test shows IMDSv1 is still accessible or an error occurs, the AI analyzes the outcome and adjusts the requirement or configuration (perhaps it missed an additional setting), then tests again. In essence, an autonomous loop where the AI: (1) generates a baseline requirement, (2) uses an AWS sandbox to deploy the service configured with the generated baseline requirement, (3) validates the deployed service instance meets the control requirement, and (4) iteratively improves the requirement based on actual results. This will be demonstrated for AWS services, proving that the approach can generalize to any service. The hackathon prototype will focus on the core logic of requirement generation and validation, with minimal external inputs (the AI primarily uses its built-in knowledge). As a stretch, we envision feeding the agent with AWS’s own documentation, API references and security control references to enhance its accuracy, but the primary innovation is the agent’s ability to generate, self-test and iterate on compliant configurations without human intervention.
Our team can provide 3 engineers to support the development effort.
Problem Statement:
Each cloud service comes with lengthy documentation, API references, recommended configurations, and compliance checks. Manually parsing every supported API call and configuration option, and then deploying countless instances of the service with various permutations of settings is extremely time-consuming and can lead to overlooked risks. Currently, ensuring a Secure Cloud Configuration Baseline (http://csconfigs/) meets the expected rigor means a C3 engineer must read through API references, identify security-relevant configuration options and various super-positions thereof, manually deploy service instances for each requirement, run tests to validate the resource configuration achieves the security requirement, decommission resources, and rinse-repeat for each potential baseline requirement. Moreover, static checklists or tools like Security Hub provide lists of controls but do not auto-validate in the context of a specific environment – you might know that “S3 buckets should have versioning and use a CMK for encryption” but it’s on the C3 engineer to implement and verify those settings. With dozens of AWS services to be reviewed, each with its own nuances and sometimes hundreds of configuration settings, the manual parsing and validation of supported config options significantly slows down the delivery of configuration baselines and introduces unnecessary risk.
In short, the problem is the absence of an intelligent, automated way to generate tailored security baseline requirements and verify them. We need a solution that can ensure recommended configurations achieve their intended security objectives.
Proposed Solution:
We propose an agentic AI system on AWS Bedrock that autonomously creates and validates security baseline requirements for any given AWS service. The solution has two main components: a Baseline Generator (LLM) and a Baseline Tester (agent). When a C3 engineer specifies an AWS service, the Baseline Generator, using a foundation model like Amazon Titan or Anthropic Claude via Bedrock, produces a list of security requirements for that service. Each requirement consists of: (1) a concise objective (e.g., “Service hardening”), (2) a description of the specific requirement (e.g., “Instance Metadata Service v1 must be disabled”), and (3) the required resource configuration in a structured form, (e.g., a JSON snippet of a compliant service configuration, such as HttpTokens: "required".
Crucially, for each generated requirement, the Baseline Tester agent will spin up a test instance of the service to validate the resource configuration. Bedrock Agents can call Lambda functions to create, configure and query AWS resources in a safe, isolated environment. The Baseline Tester will create necessary AWS resources such as VPCs and Security Groups, deploy service instances with the generated resource configuration, and perform configuration validation checks or simulated attacks to ensure the control is effective.

The agent iterates this loop: Generate requirement → Test → Refine. For example, if the test reveals that an EC2 instance with HttpTokens: "required" still allowed a metadata v1 request (perhaps due to an overlooked setting), the LLM would receive that feedback and refine the requirement (e.g., include HttpEndpoint=disabled) and test again. Only when the test confirms that IMDSv1 is truly inaccessible will the requirement be finalized as “validated.” This approach ensures each baseline control isn’t just theoretical but proven in practice.
The Bedrock agent framework will provide the LLM with the ability to observe output and adjust actions accordingly.
Value Proposition:
Our solution drastically reduces the time security engineers spend on researching and testing. We will implement the core logic for a representative service to prove out this concept. The deliverable will show that given, say, “Amazon EC2” as input, the system outputs a list of security requirements (like IMDSv2 enforcement, No public IPs, etc.), and for each, it demonstrates how the agent verified them. This agentic AI approach to cloud security is entirely novel: instead of static analysis or human-driven checks, we have the cloud itself telling us if a configuration is valid, guided by an intelligent agent.

The proposed agentic AI system delivers usable and tested secure configuration baselines with the push of a button and guarantees they actually work. This has several clear benefits:

• Time and Cost Savings: Automating baseline generation and testing means cloud teams spend far less time combing through documentation and trial-and-error validation. Instead of manually setting up tests, they get immediate feedback. This acceleration can save countless engineering hours.
• Improved Security Posture: By systematically enforcing and testing security best practices, the organization’s cloud environment becomes resilient by default. The AI may also surface less obvious configuration tweaks that humans might miss, ensuring more comprehensive coverage. All requirements are validated, so there’s high confidence that “compliant” really means secure in practice.
• Adaptive and Future-Proof: Because the system uses a generative model with access to knowledge, it can adapt to new services or new best practices quickly. The value here is avoiding the lag between a new AWS feature or threat and updating configuration baselines. The system could ingest updated AWS docs or Security Bulletins and instantly provide tested requirements. This dynamic quality ensures that the cloud environment’s security baseline remains up-to-date against emerging threats and CSP changes.
Tech Stack:
1. Python
2. AWS Lambda
3. Amazon Bedrock
4. Amazon Bedrock Agents
Expected Deliverables:
• Working Prototype Agentic GenAI system: A demonstrable interface where a user can input an AWS service name (e.g., Amazon EC2) and trigger the generation+validation process. The output will be a list of security baseline requirements for that service, each including an objective category, description, and the confirmed “good configuration” details. Importantly, the output will indicate the status of each requirement (validated or not) and notes from the agent’s test (e.g., Test passed: IMDSv1 endpoint unreachable with HttpTokens: "required").
• Example Use-Case Demo: We will prepare a concrete example (most likely with EC2). For the demo, we’ll show the AI generating requirements like “IMDSv2 must be disabled,” “EC2 instances must not have a public IP”, etc., and then highlight one or two where the agent actually performs the test. For instance, we might screen-capture or log the sequence where the agent launches an EC2 instance and tries to curl the metadata URL, showing that it gets a 401 Unauthorized (token required) – proof that the control works. This demo can be presented live or via screenshots/logs in our presentation.
• Architecture Diagram and Explanation: We will produce a diagram of our system architecture (LLM, Agent, Lambda, etc.) along with a write-up to help us communicate how the pieces fit together when presenting. It will show the flow from user input to model to agent to AWS and back.
• Hackathon Presentation Deck: A slide deck summarizing the problem, solution, architecture, and a walkthrough of the demo scenario. This is a deliverable to clearly convey what we built and why it matters. It will include our elevator pitch, problem statement, solution overview, and screenshots of the working prototype in action.

In essence, the deliverables combine a functional prototype with supportive materials to explain and verify its capabilities.
Stretch Goals:
If time permits or for future development after the hackathon, we have the following stretch goals:

• Knowledge Bases: Extend the model’s context by feeding it AWS documentation, API reference manuals, and Security Hub baseline definitions for the target service. This retrieval-augmented approach would likely improve the accuracy and completeness of requirements. For example, the agent could pull specific settings or constraints from the AWS user guide (via Bedrock Knowledge Bases or an embedded vector DB of docs) to ensure it doesn’t hallucinate config names and uses the latest recommended values. This is a natural next step to make the AI as informed as possible, though it adds complexity in parsing large docs in real-time.

• Advanced Reasoning & Explanations: Improve the agent’s ability not just to output requirements, but to explain them. This means as a stretch goal, each requirement could come with a security rationale. The agent can also maintain a reasoning trace of its actions. Exposing this trace to the user in a cleaned-up form would build trust – the user can see why the AI made a certain change after a failed test, etc. This is somewhat built-in with Bedrock Agents providing an event stream, but polishing it for end-user consumption required additional work.

• Threat Modelling: Create threat modelling on the final version of the baseline based on external resources like Hacktricks, OWASP Cloud top 10, Mitre Cloud Matrix, focusing on chaining seemingly benign configurations together.
Alignment to Strategic Goals:
• Increase velocity and delivery of configuration baselines
• Reduce time and effort needed to remediate coverage gaps for security configuration for cloud service currently used in the MS production environment. The risk is currently covered under ISS_1068306
• Allow for quicker expansion of security configuration baseline scope to include acquisitions (Etrade/Eaton Vance/PPA)
Target Users: